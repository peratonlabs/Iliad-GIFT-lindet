{
    "$id": "https://www.peratonlabs.com/r9gift.schema.json",
    "title": "PL-GIFT Algorithm Meta-Parameters",
    "technique": "Cosine-linear weight analysis",
    "technique_description": "Computes delta cosine features and classifies with a linear model",
    "technique_changes": "xxxxx",
    "technique_type": [
        "Weight Analysis"
    ],
    "commit_id": "xxxxx",
    "repo_name": "https://github.com/plgift/coslin",
    "$schema": "https://json-schema.org/draft-07/schema",
    "description": "TrojAI schema for the GIFT team, cos-lin method",
    "type": "object",
    "required": [
        "train_$RobertaForQuestionAnswering_103$nfeats",
        "train_$RobertaForQuestionAnswering_103$ntensors",
        "train_$RobertaForQuestionAnswering_103$cls_type",
        "train_$RobertaForQuestionAnswering_103$param_batch_sz",
        "train_$RobertaForQuestionAnswering_103$C",
        "train_$RobertaForQuestionAnswering_103$feature_selection_criterion",
        "train_$RobertaForQuestionAnswering_103$features",
        "train_$RobertaForQuestionAnswering_103$normalize_for_feature_selection",
        "train_$RobertaForQuestionAnswering_103$sort_tensors",
        "train_$RobertaForQuestionAnswering_199$nfeats",
        "train_$RobertaForQuestionAnswering_199$ntensors",
        "train_$RobertaForQuestionAnswering_199$cls_type",
        "train_$RobertaForQuestionAnswering_199$param_batch_sz",
        "train_$RobertaForQuestionAnswering_199$C",
        "train_$RobertaForQuestionAnswering_199$feature_selection_criterion",
        "train_$RobertaForQuestionAnswering_199$features",
        "train_$RobertaForQuestionAnswering_199$normalize_for_feature_selection",
        "train_$RobertaForQuestionAnswering_199$sort_tensors",
        "train_$MobileBertForQuestionAnswering_1113$nfeats",
        "train_$MobileBertForQuestionAnswering_1113$ntensors",
        "train_$MobileBertForQuestionAnswering_1113$cls_type",
        "train_$MobileBertForQuestionAnswering_1113$param_batch_sz",
        "train_$MobileBertForQuestionAnswering_1113$C",
        "train_$MobileBertForQuestionAnswering_1113$feature_selection_criterion",
        "train_$MobileBertForQuestionAnswering_1113$features",
        "train_$MobileBertForQuestionAnswering_1113$normalize_for_feature_selection",
        "train_$MobileBertForQuestionAnswering_1113$sort_tensors"
    ],
    "additionalProperties": false,
    "properties": {
        "train_$RobertaForQuestionAnswering_103$nfeats": {
            "type": "integer",
            "minimum": 1,
            "description": "how many features to select",
            "suggested_minimum": 50,
            "suggested_maximum": 5000
        },
        "train_$RobertaForQuestionAnswering_103$ntensors": {
            "type": "integer",
            "minimum": 0,
            "description": "how many tensors select features from",
            "suggested_minimum": 5,
            "suggested_maximum": 100
        },
        "train_$RobertaForQuestionAnswering_103$cls_type": {
            "enum": [
                "LogisticRegression"
            ],
            "description": "name of classifier class (only LogisticRegression is currently supported)"
        },
        "train_$RobertaForQuestionAnswering_103$param_batch_sz": {
            "type": "integer",
            "minimum": 1,
            "description": "how many torch 'parameters' to look at at a time (trade off memory and disk reading)",
            "suggested_minimum": 80,
            "suggested_maximum": 80
        },
        "train_$RobertaForQuestionAnswering_103$C": {
            "type": "number",
            "minimum": 1e-09,
            "description": "sklearn-style regularization term.  Higher C -> less regularization. Must be positive",
            "suggested_minimum": 0.01,
            "suggested_maximum": 200.0
        },
        "train_$RobertaForQuestionAnswering_103$feature_selection_criterion": {
            "enum": [
                "corr",
                "auc"
            ],
            "description": "criterion for greedy feature selection"
        },
        "train_$RobertaForQuestionAnswering_103$features": {
            "enum": [
                "raw",
                "white_delta",
                "cosine_delta",
                "pnorm_delta",
                "white",
                "cosine",
                "pnorm"
            ],
            "description": "preprocessing options. Normalize by stdev (white) or L2 (cosine) or None. Use raw or 'delta' from pretrained reference model"
        },
        "train_$RobertaForQuestionAnswering_103$normalize_for_feature_selection": {
            "type": "boolean",
            "description": "whether or not to apply normalization before feature selection"
        },
        "train_$RobertaForQuestionAnswering_103$sort_tensors": {
            "type": "boolean",
            "description": "whether or not to sort tensors"
        },
        "train_$RobertaForQuestionAnswering_199$nfeats": {
            "type": "integer",
            "minimum": 1,
            "description": "how many features to select",
            "suggested_minimum": 50,
            "suggested_maximum": 5000
        },
        "train_$RobertaForQuestionAnswering_199$ntensors": {
            "type": "integer",
            "minimum": 0,
            "description": "how many tensors select features from",
            "suggested_minimum": 5,
            "suggested_maximum": 100
        },
        "train_$RobertaForQuestionAnswering_199$cls_type": {
            "enum": [
                "LogisticRegression"
            ],
            "description": "name of classifier class (only LogisticRegression is currently supported)"
        },
        "train_$RobertaForQuestionAnswering_199$param_batch_sz": {
            "type": "integer",
            "minimum": 1,
            "description": "how many torch 'parameters' to look at at a time (trade off memory and disk reading)",
            "suggested_minimum": 80,
            "suggested_maximum": 80
        },
        "train_$RobertaForQuestionAnswering_199$C": {
            "type": "number",
            "minimum": 1e-09,
            "description": "sklearn-style regularization term.  Higher C -> less regularization. Must be positive",
            "suggested_minimum": 0.01,
            "suggested_maximum": 200.0
        },
        "train_$RobertaForQuestionAnswering_199$feature_selection_criterion": {
            "enum": [
                "corr",
                "auc"
            ],
            "description": "criterion for greedy feature selection"
        },
        "train_$RobertaForQuestionAnswering_199$features": {
            "enum": [
                "raw",
                "white_delta",
                "cosine_delta",
                "pnorm_delta",
                "white",
                "cosine",
                "pnorm"
            ],
            "description": "preprocessing options. Normalize by stdev (white) or L2 (cosine) or None. Use raw or 'delta' from pretrained reference model"
        },
        "train_$RobertaForQuestionAnswering_199$normalize_for_feature_selection": {
            "type": "boolean",
            "description": "whether or not to apply normalization before feature selection"
        },
        "train_$RobertaForQuestionAnswering_199$sort_tensors": {
            "type": "boolean",
            "description": "whether or not to sort tensors"
        },
        "train_$MobileBertForQuestionAnswering_1113$nfeats": {
            "type": "integer",
            "minimum": 1,
            "description": "how many features to select",
            "suggested_minimum": 50,
            "suggested_maximum": 5000
        },
        "train_$MobileBertForQuestionAnswering_1113$ntensors": {
            "type": "integer",
            "minimum": 0,
            "description": "how many tensors select features from",
            "suggested_minimum": 5,
            "suggested_maximum": 100
        },
        "train_$MobileBertForQuestionAnswering_1113$cls_type": {
            "enum": [
                "LogisticRegression"
            ],
            "description": "name of classifier class (only LogisticRegression is currently supported)"
        },
        "train_$MobileBertForQuestionAnswering_1113$param_batch_sz": {
            "type": "integer",
            "minimum": 1,
            "description": "how many torch 'parameters' to look at at a time (trade off memory and disk reading)",
            "suggested_minimum": 80,
            "suggested_maximum": 80
        },
        "train_$MobileBertForQuestionAnswering_1113$C": {
            "type": "number",
            "minimum": 1e-09,
            "description": "sklearn-style regularization term.  Higher C -> less regularization. Must be positive",
            "suggested_minimum": 0.01,
            "suggested_maximum": 200.0
        },
        "train_$MobileBertForQuestionAnswering_1113$feature_selection_criterion": {
            "enum": [
                "corr",
                "auc"
            ],
            "description": "criterion for greedy feature selection"
        },
        "train_$MobileBertForQuestionAnswering_1113$features": {
            "enum": [
                "raw",
                "white_delta",
                "cosine_delta",
                "pnorm_delta",
                "white",
                "cosine",
                "pnorm"
            ],
            "description": "preprocessing options. Normalize by stdev (white) or L2 (cosine) or None. Use raw or 'delta' from pretrained reference model"
        },
        "train_$MobileBertForQuestionAnswering_1113$normalize_for_feature_selection": {
            "type": "boolean",
            "description": "whether or not to apply normalization before feature selection"
        },
        "train_$MobileBertForQuestionAnswering_1113$sort_tensors": {
            "type": "boolean",
            "description": "whether or not to sort tensors"
        }
    }
}